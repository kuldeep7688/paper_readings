# Papers and their Summaries

## 1. Active Learning Principles for In-Context Learning with Large Language Models

[Semantic Scholar Link](https://www.semanticscholar.org/reader/91c37a88c2b320725057260677ae79f3cdaa492b) | [Arxiv Link](https://arxiv.org/abs/2305.14264)

### Main Idea

1. Selection of in-context learning examples using Active Learning approaches uncertainity, diversity, similarity and random sampling. (in a single iteration setting)
2. Experiments done on 15 models and 15 Classificationa and 9 mcq tasks
3. Uncertainity based sampling done using SPELL algorithm. Used perplexity, low perplexity set of in-context examples can yield better results.
4. Similarity : using KATE (KNN, augmented) with Sentence-Bert embeddings.
5. use K = 16 in prompting K-Shot.

### Datasets Used

### Anything I can add upon that

1. Using sophisticated algorithms like Q-learning, Self Adaptive, SG-ICL and MI in AL paradigm.

---

##

[Semantic Scholar Link]() | [Arxiv Link]()

### Main Idea

1.

### Datasets Used

-

### Anything I can add upon that

1.

-

##

[Semantic Scholar Link]() | [Arxiv Link]()

### Main Idea

1.

### Datasets Used

-

### Anything I can add upon that

1.

---

##

[Semantic Scholar Link]() | [Arxiv Link]()

### Main Idea

1.

### Datasets Used

-

### Anything I can add upon that

1.
